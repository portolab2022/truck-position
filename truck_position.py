# -*- coding: utf-8 -*-
"""Truck_Position.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V4h4sQY05pZZmNMBtBrUezTJW4qGxat7
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required libraries
!pip install ultralytics -q

from ultralytics import YOLO
import os

# Define paths (update based on your Google Drive folder structure)
data_folder = '/content/drive/My Drive/tr.la.v3i.yolov8/train'
image_folder = os.path.join(data_folder, 'images')
label_folder = os.path.join(data_folder, 'labels')
output_folder = os.path.join(data_folder, 'yolov8_training')

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Create a YAML file for dataset configuration
yaml_content = f"""
train: {image_folder}
val: {image_folder}  # Use the same folder for simplicity; split can be done in Roboflow
nc: 2  # Number of classes (front and side)
names: ['front', 'side']  # Class names
"""
with open(os.path.join(data_folder, 'data.yaml'), 'w') as f:
    f.write(yaml_content)

# Load a pre-trained YOLOv8 model (e.g., yolov8n for nano size)
model = YOLO('yolov8n.pt')

# Train the model
model.train(
    data=os.path.join(data_folder, 'data.yaml'),
    epochs=50,
    imgsz=640,
    batch=16,
    project=output_folder,
    name='truck_detection',
    exist_ok=True
)

# Save the best weights
best_weights = os.path.join(output_folder, 'truck_detection', 'weights', 'best.pt')
print(f"Training completed. Best weights saved at: {best_weights}")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required libraries
!pip install ultralytics -q

from ultralytics import YOLO
import os
import cv2
from matplotlib import pyplot as plt

# Define paths (update based on your Google Drive folder structure)
model_path = '/content/drive/My Drive/tr.la.v3i.yolov8/train/yolov8_training/truck_detection/weights/best.pt'  # Path to trained weights
image_folder = '/content/drive/My Drive/tr.la.v3i.yolov8/new_truck_images'  # Folder with new images

# Load the trained model
model = YOLO(model_path)

# Process new images
for filename in os.listdir(image_folder):
    if filename.endswith('.jpg') or filename.endswith('.png'):
        image_path = os.path.join(image_folder, filename)

        # Read image
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Perform inference
        results = model(image)

        # Extract detections
        info = []
        for result in results[0].boxes:
            class_id = int(result.cls[0])
            x, y, w, h = result.xywh[0]
            centroid_x, centroid_y = x / image.shape[1], y / image.shape[0]  # Normalize
            if class_id == 0:
                info.append(f"Front detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")
            elif class_id == 1:
                info.append(f"Side detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")

        # Display results
        plt.figure(figsize=(10, 5))
        plt.imshow(image)
        plt.title(f"Image: {filename}\n{' | '.join(info) if info else 'No front or side detected'}")
        plt.axis('off')
        plt.show()

        if info:
            print(f"Info for {filename}: {', '.join(info)}")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required libraries
!pip install ultralytics -q

from ultralytics import YOLO
import os
import cv2
from matplotlib import pyplot as plt

# Define paths (update based on your Google Drive folder structure)
model_path = '/content/drive/My Drive/tr.la.v3i.yolov8/train/yolov8_training/truck_detection/weights/best.pt'  # Path to trained weights
image_folder = '/content/drive/My Drive/tr.la.v3i.yolov8/new_truck_images'  # Folder with new images

# Load the trained model
model = YOLO(model_path)

# Process new images
for filename in os.listdir(image_folder):
    if filename.endswith('.jpg') or filename.endswith('.png'):
        image_path = os.path.join(image_folder, filename)

        # Read image
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # For Matplotlib display
        image_bgr = image.copy()  # For OpenCV drawing

        # Perform inference
        results = model(image)

        # Extract detections and draw front bounding box
        info = []
        for result in results[0].boxes:
            class_id = int(result.cls[0])
            x, y, w, h = result.xywh[0]
            centroid_x, centroid_y = x / image.shape[1], y / image.shape[0]  # Normalize
            x1 = int((x - w / 2) / image.shape[1] * image.shape[1])  # Top-left x
            y1 = int((y - h / 2) / image.shape[0] * image.shape[0])  # Top-left y
            x2 = int((x + w / 2) / image.shape[1] * image.shape[1])  # Bottom-right x
            y2 = int((y + h / 2) / image.shape[0] * image.shape[0])  # Bottom-right y

            if class_id == 0:  # Assuming 0 is front
                info.append(f"Front detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")
                # Draw bounding box (green for front)
                cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
                # Add centroid point (red dot)
                cv2.circle(image_bgr, (int(x), int(y)), 5, (0, 0, 255), -1)
            elif class_id == 1:  # Assuming 1 is side
                info.append(f"Side detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")

        # Convert BGR back to RGB for display
        image_display = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        # Display results
        plt.figure(figsize=(10, 5))
        plt.imshow(image_display)
        plt.title(f"Image: {filename}\n{' | '.join(info) if info else 'No front or side detected'}")
        plt.axis('off')
        plt.show()

        if info:
            print(f"Info for {filename}: {', '.join(info)}")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required libraries
!pip install ultralytics -q

from ultralytics import YOLO
import os
import cv2
from matplotlib import pyplot as plt

# Define paths (update based on your Google Drive folder structure)
model_path = '/content/drive/My Drive/tr.la.v3i.yolov8/train/yolov8_training/truck_detection/weights/best.pt'  # Path to trained weights
image_folder = '/content/drive/My Drive/tr.la.v3i.yolov8/new_truck_images'  # Folder with new images


# Load the trained model
model = YOLO(model_path)

# Define correct position criteria (adjusted based on feedback)
CORRECT_X_RANGE = (0.4, 0.7)  # Includes 0.57
CORRECT_Y_RANGE = (0.4, 0.7)  # Includes 0.55
# Note: Validate these ranges with your full dataset for accuracy.

# Process new images
for filename in os.listdir(image_folder):
    if filename.endswith('.jpg') or filename.endswith('.png'):
        image_path = os.path.join(image_folder, filename)

        # Read image
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # For Matplotlib display
        image_bgr = image.copy()  # For OpenCV drawing

        # Perform inference
        results = model(image)

        # Extract detections and check position
        info = []
        position_status = "Unknown"
        for result in results[0].boxes:
            class_id = int(result.cls[0])
            x, y, w, h = result.xywh[0]
            centroid_x, centroid_y = x / image.shape[1], y / image.shape[0]  # Normalize
            x1 = int((x - w / 2) / image.shape[1] * image.shape[1])  # Top-left x
            y1 = int((y - h / 2) / image.shape[0] * image.shape[0])  # Top-left y
            x2 = int((x + w / 2) / image.shape[1] * image.shape[1])  # Bottom-right x
            y2 = int((y + h / 2) / image.shape[0] * image.shape[0])  # Bottom-right y

            if class_id == 0:  # Front
                info.append(f"Front detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")
                cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box
                cv2.circle(image_bgr, (int(x), int(y)), 5, (0, 0, 255), -1)  # Red centroid
                # Check position
                is_within_bounds = (0 <= x1 <= image.shape[1] and 0 <= y1 <= image.shape[0] and
                                  0 <= x2 <= image.shape[1] and 0 <= y2 <= image.shape[0])
                if (CORRECT_X_RANGE[0] <= centroid_x <= CORRECT_X_RANGE[1] and
                    CORRECT_Y_RANGE[0] <= centroid_y <= CORRECT_Y_RANGE[1] and
                    is_within_bounds):
                    position_status = "Correct"
                else:
                    position_status = "Incorrect"
            elif class_id == 1:  # Side
                info.append(f"Side detected at (centroid: {centroid_x:.2f}, {centroid_y:.2f})")

        # Convert BGR back to RGB for display
        image_display = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        # Display results
        plt.figure(figsize=(10, 5))
        plt.imshow(image_display)
        plt.title(f"Image: {filename}\n{' | '.join(info) if info else 'No front or side detected'}\nPosition: {position_status}")
        plt.axis('off')
        plt.show()

        if info:
            print(f"Info for {filename}: {', '.join(info)}, Position: {position_status}")